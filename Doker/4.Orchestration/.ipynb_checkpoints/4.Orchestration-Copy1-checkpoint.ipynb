{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://lssds.aura-astronomy.org/winter_school/sites/default/files/sods_atfdds_header01.jpg\" alt=\"La Serena School for Data Science: Applied Tools for Data-driven Sciences\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Container orchestration:\n",
    "\n",
    "Container orchestration in the context of Docker refers to the management and automation of multiple containers within a distributed environment. It's a crucial aspect of DevOps and modern application deployment, especially when dealing with large-scale applications that are composed of multiple microservices or containers. Container orchestration tools help automate tasks like deployment, scaling, networking, load balancing, and more, making it easier to manage and maintain complex applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![https://www.linkedin.com/pulse/top-10-container-orchestration-tools-sandeep-kumar-patel/](images/top10.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the motivation to use container orchestration?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The motivation to use container orchestration in Docker arises from the need to efficiently manage and operate complex applications composed of multiple containers. As applications grow in scale and complexity, manual management becomes impractical and error-prone. Container orchestration provides a solution by automating deployment, scaling, management, and monitoring of containerized applications. Here are the key motivations for using container orchestration in Docker:\n",
    "\n",
    "1. **Scalability:** Container orchestration allows applications to scale dynamically based on demand. As traffic increases, new container instances can be automatically launched, and as demand decreases, excess containers can be scaled down. This ensures optimal resource utilization and responsiveness.\n",
    "\n",
    "2. **High Availability:** Orchestration tools distribute containers across multiple nodes, ensuring that if one node or container fails, the application remains operational by rescheduling containers on healthy nodes. This enhances availability and minimizes downtime.\n",
    "\n",
    "3. **Efficient Resource Utilization:** Orchestration platforms optimize resource allocation by scheduling containers to run on nodes with available resources. This prevents resource wastage and maximizes hardware utilization.\n",
    "\n",
    "4. **Simplified Deployment:** Container orchestration automates the deployment process, allowing consistent and reliable application rollout across environments. This reduces human errors and accelerates the deployment pipeline.\n",
    "\n",
    "5. **Load Balancing:** Orchestration tools provide built-in load balancing mechanisms that distribute incoming traffic across healthy containers. This ensures even distribution of requests and prevents overload on specific containers.\n",
    "\n",
    "6. **Self-Healing:** Orchestration platforms continuously monitor the health of containers. If a container becomes unhealthy or fails, the orchestration system automatically replaces it with a new instance. This maintains application availability.\n",
    "\n",
    "7. **Rolling Updates and Rollbacks:** Orchestration simplifies the process of updating applications by enabling rolling updates, where new versions are deployed gradually, ensuring zero-downtime updates. If issues arise, easy rollbacks can be performed.\n",
    "\n",
    "8. **Service Discovery:** As containers are dynamically created and destroyed, orchestration systems provide service discovery mechanisms, making it easy for containers to locate and communicate with each other.\n",
    "\n",
    "9. **Consistent Environment:** Orchestration tools ensure that the environment for each container is consistent across the cluster, from configuration settings to software dependencies. This eliminates inconsistencies that can lead to application failures.\n",
    "\n",
    "10. **Infrastructure Agnosticism:** Orchestration platforms abstract underlying infrastructure, allowing applications to run seamlessly on various cloud providers or on-premises environments without modification.\n",
    "\n",
    "11. **Automated Scaling Policies:** Orchestration platforms enable setting up automated scaling policies based on metrics like CPU usage or memory consumption. This ensures that the application scales up or down based on predefined rules.\n",
    "\n",
    "12. **Security:** Orchestration systems offer security features such as network segmentation, access controls, and secrets management to protect containerized applications.\n",
    "\n",
    "13. **DevOps Practices:** Container orchestration integrates well with DevOps practices, enabling continuous integration, continuous deployment, and infrastructure as code (IaC) methodologies.\n",
    "\n",
    "In essence, the motivation to use container orchestration in Docker is to address the challenges of managing complex applications at scale. It empowers organizations to achieve better resource utilization, higher availability, efficient deployments, and improved collaboration between development and operations teams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Container orchestration in Docker involves:\n",
    "___\n",
    "\n",
    "\n",
    "1. **Deployment Automation:** Orchestration tools automate the process of deploying containerized applications across a cluster of machines. They manage the deployment of containers to ensure that the desired number of replicas are running and healthy.\n",
    "\n",
    "2. **Scaling:** Orchestration allows you to scale your application horizontally by adding or removing instances of containers as demand fluctuates. This is done automatically based on predefined rules or metrics.\n",
    "\n",
    "3. **Load Balancing:** Orchestration tools distribute incoming traffic across multiple container instances to ensure even distribution and efficient use of resources.\n",
    "\n",
    "4. **Service Discovery:** As containers are dynamically created and destroyed, orchestration tools help maintain a central registry of running services and their associated containers. This enables easy discovery of services within the cluster.\n",
    "\n",
    "5. **Rolling Updates and Rollbacks:** Orchestration simplifies the process of updating applications by deploying new container versions gradually and ensuring zero-downtime updates. In case of issues, it facilitates easy rollbacks.\n",
    "\n",
    "6. **High Availability:** Orchestration ensures high availability by distributing containers across multiple nodes. If a node fails, the orchestration system automatically reschedules containers on healthy nodes.\n",
    "\n",
    "7. **Networking:** Orchestration tools manage container networking, ensuring that containers can communicate with each other within and across nodes.\n",
    "\n",
    "8. **Storage Management:** Some orchestration solutions provide mechanisms for managing persistent storage for containers, ensuring that data is retained even when containers are replaced.\n",
    "\n",
    "9. **Health Checks and Self-Healing:** Orchestration platforms continuously monitor the health of containers. If a container fails or becomes unhealthy, the orchestration system automatically replaces it with a new instance.\n",
    "\n",
    "10. **Configuration Management:** Orchestration tools can manage environment variables, secrets, and other configuration settings for containers, ensuring consistent configurations across the cluster.\n",
    "\n",
    "11. **Security:** Orchestration tools implement security measures like network segmentation, access controls, and encryption to protect the containerized applications.\n",
    "\n",
    "12. **Integration with CI/CD:** Orchestration is often integrated into continuous integration and continuous deployment (CI/CD) pipelines, automating the deployment of new code changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Popular Docker container orchestration tools include:\n",
    "\n",
    "- **[Kubernetes](https://kubernetes.io/):** An open-source platform for automating deployment, scaling, and management of containerized applications.\n",
    "\n",
    "- **[Docker Swarm](https://docs.docker.com/engine/swarm/):** A native clustering and orchestration solution from Docker, designed to work seamlessly with Docker containers.\n",
    "\n",
    "- **[Apache Mesos](https://mesos.apache.org/):** A distributed systems kernel that abstracts CPU, memory, storage, and other resources, allowing efficient resource utilization across clusters.\n",
    "\n",
    "\n",
    "\n",
    "**Summary:** container orchestration in Docker involves automating the management of containerized applications across a cluster of machines. It streamlines deployment, scaling, load balancing, and other operational tasks, making it easier to manage complex applications in dynamic and distributed environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Deploying Jupyter Notebook Services with Docker Swarm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through an example of how you could use Docker Swarm to deploy Jupyter Notebook instances for collaborative data analysis and programming. In this scenario, we'll set up a Docker Swarm cluster and deploy Jupyter Notebook services for multiple users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Initialization:** First, you'll need to initialize a Docker Swarm on a host machine. You can do this using the `docker swarm init` command. This host will become the Swarm manager.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node left the swarm.\r\n"
     ]
    }
   ],
   "source": [
    "#!docker swarm leave --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swarm initialized: current node (a4j3omg05vnb7jbcxj7ut8jnd) is now a manager.\r\n",
      "\r\n",
      "To add a worker to this swarm, run the following command:\r\n",
      "\r\n",
      "    docker swarm join --token SWMTKN-1-3izq7lha7qjxcecohe69lrzfsrwe1hcb0pukhm7hytfd6ygheo-5o0ckcrjanlvpqf5kibblevky 192.168.65.4:2377\r\n",
      "\r\n",
      "To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!docker swarm init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. **Deploy nginx Service:**\n",
    "   You'll need a Docker image that includes Jupyter Notebook and any required libraries. Let's assume you have this image named `nginx-image`. Deploy the Jupyter Notebook service using the following command:\n",
    "   ```bash\n",
    "   docker service create --name nginx --publish mode=host,target=80,published=8080 nginx:latest\n",
    "   ```\n",
    "   This creates a nginx service named `nginx` that runs on port 80 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image nginx:latest could not be accessed on a registry to record\n",
      "its digest. Each node will access nginx:latest independently,\n",
      "possibly leading to different nodes running different\n",
      "versions of the image.\n",
      "\n",
      "t75ujdo13opkeops0q86yoihd\n",
      "\n",
      "\u001b[1Ball progress: 0 out of 3 tasks \n",
      "\u001b[1B   K\n",
      "\u001b[1B   K\n",
      "\u001b[4Ball progress: 1 out of 3 tasks rt already in use on 1 node) \u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2K\u001b[1A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2Kno suitable node (host-mode port already in use on 1 node) \u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K^C\n",
      "Operation continuing in background.\n",
      "Use `docker service ps t75ujdo13opkeops0q86yoihd` to check progress.\n"
     ]
    }
   ],
   "source": [
    "!docker service create \\\n",
    "  --publish mode=host,target=80,published=8080 \\\n",
    "  --name=nginx \\\n",
    "  nginx:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE          COMMAND                  CREATED              STATUS              PORTS                  NAMES\r\n",
      "383de00b3b9b   nginx:latest   \"/docker-entrypoint.â€¦\"   About a minute ago   Up About a minute   0.0.0.0:8080->80/tcp   nginx.1.z4391wpzo7vr5mtth8xe9eqv1\r\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. **Load Balancing:**\n",
    "   Docker Swarm automatically distributes incoming traffic to the replicas of the `nginx` service, providing load balancing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5. **Data Persistence:**\n",
    "   To ensure data persistence, you can mount a volume to the nginx container. This way, user data will be retained even if a container is replaced. Use the `-v` flag when creating the service.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "6. **Updating Services:**\n",
    "   If you need to update the nginx image with new libraries or features, you can do so by building a new image and updating the service:\n",
    "   ```bash\n",
    "   docker service update --image new-nginx-image nginx\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "9. **Scaling and Management:**\n",
    "   You can continue scaling the `nginx` service as needed to accommodate more users. Docker Swarm will manage the distribution of instances across nodes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. **High Availability:**\n",
    "   If a node fails, Docker Swarm will ensure that the service continues to run by rescheduling replicas on healthy nodes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. **Removing Services:**\n",
    "    When you're finished, you can remove the `nginx` service and the overlay network using the `docker service rm` and `docker network rm` commands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nginx\r\n"
     ]
    }
   ],
   "source": [
    "!docker service rm nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using Docker Swarm to deploy Jnginx instances, you can provide a collaborative environment for data analysis and programming. The orchestration features of Docker Swarm simplify the management of nginx services, ensuring scalability, load balancing, and high availability for your users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

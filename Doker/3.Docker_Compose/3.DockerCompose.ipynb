{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://lssds.aura-astronomy.org/winter_school/sites/default/files/sods_atfdds_header01.jpg\" alt=\"La Serena School for Data Science: Applied Tools for Data-driven Sciences\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to Docker Compose:\n",
    "\n",
    "Docker Compose is a tool that enables you to define and manage multi-container Docker applications. It allows you to describe the entire application stack, including multiple services, networks, and volumes, in a single YAML file. This theoretical introduction will help you understand the fundamental concepts of Docker Compose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tcude.net/content/images/2022/01/MainImage-2.jpeg\" alt=\"La Serena School for Data Science: Applied Tools for Data-driven Sciences\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Simplifying Multi-Container Applications:\n",
    "---\n",
    "\n",
    "- Many modern applications are composed of multiple services, each running in its own container. These services often need to communicate and interact with each other.\n",
    "- Docker Compose simplifies the process of managing and coordinating these multi-container applications by allowing you to define and control the entire stack with a single configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Docker Compose YAML File:\n",
    "___\n",
    "\n",
    "- A Docker Compose YAML file (***docker-compose.yml***) is used to define the components of a multi-container application. It specifies services, networks, volumes, and other configurations.\n",
    "- The YAML file is human-readable and allows you to define the relationships, dependencies, and settings for each service in your application stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Services:\n",
    "___\n",
    "- A service is a unit of an application defined in the Docker Compose YAML file. It corresponds to a container and defines how the container should be configured and run.\n",
    "- Each service in the ***docker-compose.yml*** file can have its own image, environment variables, ports, volumes, and other settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Networks:\n",
    "___\n",
    "- Docker Compose allows you to create custom networks for your services. Networks enable communication between services while isolating them from external traffic.\n",
    "- Services within the same network can communicate using service names as hostnames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Volumes:\n",
    "___\n",
    "- Volumes in Docker Compose allow you to persist and share data between containers. They are used to store data that needs to persist beyond the container's lifecycle.\n",
    "- Volumes are particularly useful for database containers or containers with important configuration files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Advantages of Docker Compose:\n",
    "___\n",
    "- **Simplicity:** Docker Compose abstracts away the complexity of managing multiple containers, making it easier to define and maintain complex application stacks.\n",
    "- **Reproducibility:** With a single docker-compose.yml file, you can define the entire application stack, ensuring consistency across environments.\n",
    "- **Portability:** Docker Compose configurations can be versioned and shared, allowing teams to collaborate and ensure that the same application runs consistently everywhere.\n",
    "- **Isolation:** Services in Docker Compose run in isolated containers, providing process-level isolation while allowing seamless communication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. Use Cases:\n",
    "___\n",
    "- Docker Compose is particularly useful for development and testing environments, where you need to quickly spin up an entire application stack for local testing or debugging.\n",
    "- It's also valuable for creating repeatable setups for continuous integration and deployment pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Verify Docker Compose Installation:\n",
    "___\n",
    "After installing Docker Desktop, you should have Docker Compose automatically available. To verify the installation, open a terminal and run the following command:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker Compose version v2.17.2\r\n"
     ]
    }
   ],
   "source": [
    "!docker-compose --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: \n",
    "___\n",
    "Docker Compose simplifies the management of multi-container applications by providing a declarative way to define and orchestrate services, networks, and volumes. It's a valuable tool for both developers and DevOps teams to streamline the deployment and testing of complex applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Your First Docker Container:\n",
    "___\n",
    "\n",
    "\n",
    "### Step 1: Create a Directory for Your Project:\n",
    "Open a terminal and create a new directory for your Dask cluster project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir dask-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd dask-cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a docker-compose.yml File:\n",
    "\n",
    "Inside your project directory, create a file named **docker-compose.yml** using a text editor of your choice. This file will define your Dask cluster configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define Services in docker-compose.yml:\n",
    "\n",
    "Add the following content to your docker-compose.yml file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: '3'\r\n",
      "services:\r\n",
      "  scheduler:\r\n",
      "    image: daskdev/dask:latest\r\n",
      "    command: [\"dask-scheduler\"]\r\n",
      "    ports:\r\n",
      "      - \"8786:8786\"\r\n",
      "\r\n",
      "  worker:\r\n",
      "    image: daskdev/dask:latest\r\n",
      "    command: [\"dask-worker\", \"scheduler:8786\"]\r\n",
      "    depends_on:\r\n",
      "      - scheduler"
     ]
    }
   ],
   "source": [
    "!cat dask-cluster/docker-compose.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This configuration defines two services: **scheduler** and **worker**.\n",
    "\n",
    "- The ***scheduler*** service uses the ***daskdev/dask*** image and starts the Dask scheduler using the dask-scheduler command. It exposes port 8786 for communication.\n",
    "- The ***worker*** service also uses the same image and starts a Dask worker using the ***dask-worker*** command. It depends on the ***scheduler*** service and connects to the scheduler's port 8786."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Start the Dask Cluster:\n",
    "\n",
    "In your terminal, navigate to your project directory and run the following command to start the Dask cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\r\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker-compose up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the docker-compose up command with the -f or --file option followed by the path to your docker-compose.yml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 2/0\n",
      " \u001b[32m✔\u001b[0m Container dask-cluster-scheduler-1  \u001b[32mCreated\u001b[0m                             \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m✔\u001b[0m Container dask-cluster-worker-1     \u001b[32mCreated\u001b[0m                             \u001b[34m0.0s \u001b[0m\n",
      "\u001b[?25hAttaching to dask-cluster-scheduler-1, dask-cluster-worker-1\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0mno environment.yml\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ '[' '' ']'\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ '[' '' == true ']'\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ CONDA_BIN=/opt/conda/bin/conda\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ '[' -e /opt/app/environment.yml ']'\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ echo 'no environment.yml'\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ '[' '' ']'\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ '[' '' ']'\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ exec dask-scheduler\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0mno environment.yml\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ '[' '' ']'\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ '[' '' == true ']'\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ CONDA_BIN=/opt/conda/bin/conda\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ '[' -e /opt/app/environment.yml ']'\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ echo 'no environment.yml'\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ '[' '' ']'\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ '[' '' ']'\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ exec dask-worker scheduler:8786\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m/opt/conda/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:142: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m  warnings.warn(\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:12,165 - distributed.scheduler - INFO - -----------------------------------------------\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m/opt/conda/lib/python3.10/site-packages/distributed/cli/dask_worker.py:266: FutureWarning: dask-worker is deprecated and will be removed in a future release; use `dask worker` instead\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m  warnings.warn(\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:12,624 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:12,672 - distributed.scheduler - INFO - State start\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:12,678 - distributed.scheduler - INFO - -----------------------------------------------\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:12,679 - distributed.scheduler - INFO -   Scheduler at:     tcp://172.22.0.2:8786\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:12,680 - distributed.scheduler - INFO -   dashboard at:  http://172.22.0.2:8787/status\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:12,698 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.22.0.3:35295'\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,639 - distributed.worker - INFO -       Start worker at:     tcp://172.22.0.3:34997\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,639 - distributed.worker - INFO -          Listening to:     tcp://172.22.0.3:34997\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,639 - distributed.worker - INFO -          dashboard at:           172.22.0.3:36379\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,639 - distributed.worker - INFO - Waiting to connect to:       tcp://scheduler:8786\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,639 - distributed.worker - INFO - -------------------------------------------------\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,640 - distributed.worker - INFO -               Threads:                          4\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,640 - distributed.worker - INFO -                Memory:                   7.68 GiB\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,640 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r4mya_7x\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,640 - distributed.worker - INFO - -------------------------------------------------\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:14,142 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.22.0.3:34997', status: init, memory: 0, processing: 0>\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:14,583 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.22.0.3:34997\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:14,584 - distributed.core - INFO - Starting established connection to tcp://172.22.0.3:54926\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:14,584 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:14,585 - distributed.worker - INFO -         Registered to:       tcp://scheduler:8786\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:14,585 - distributed.worker - INFO - -------------------------------------------------\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:14,587 - distributed.core - INFO - Starting established connection to tcp://scheduler:8786\n",
      "^C\n",
      "Gracefully stopping... (press Ctrl+C again to force)\n",
      "Aborting on container exit...\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/0\n",
      " ⠋ Container dask-cluster-worker-1  \u001b[39mS...\u001b[0m                                   \u001b[34m0.1s \u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!docker-compose -f dask-cluster/docker-compose.yml up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker Compose will pull the necessary images and start the scheduler and worker containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Check the cluster:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Stop the Cluster:\n",
    "\n",
    "To stop the Dask cluster, press **Ctrl+C** in the terminal where you started the cluster with docker-compose up.\n",
    "\n",
    "### Step 7: Clean Up:\n",
    "\n",
    "If you want to remove the containers and network created by Docker Compose, run the following command in your project directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no configuration file provided: not found\r\n"
     ]
    }
   ],
   "source": [
    "!docker-compose down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "That's it! You've created a Docker Compose configuration for a Python Dask cluster. This setup allows you to easily manage and scale your Dask cluster for distributed computing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
